1. Username and emails
colin_t(colin_t@mit.edu), sherwu (sherwu@mit.edu), brianb (brianb@mit.edu)

2. Teammates 
Colin Taylor, Sherwin Wu, Brian Bell

3. Describe your entity resolution technique, as well as its precision, recall, and F1 score.
Our technique relies upon scoring how similar two entries are and comparing it to a threshold. We compare the latitude/longitude within a threshold. We compare the exact matches of  name, zipcode, phone and website (after some cleanup). We also use the Jaccard distance of the name, and address. Since latitude/longitude, or a combination of address/zip, or name and phone are very specific, we deem it a match if combinations of these are the same. Otherwise we weight the value of each type of match and add the terms to obtain a total value. If that value exceeds the threshold, then enough of the data from the two entries is alike to call them a match.

What were the most important features that powered your technique?
The key features included some very strategic cleaning up/standardization of web URLs, addresses and names, in addition to Jaccard distance and iterative threshold optimization. This cleanup included cleaning up abbreviations, different storing techniques (null vs empty string), removing forward slashes and moving to lower case.

How did you avoid pairwise comparison of all venues across both datasets?
To avoid pairwise comparison, we broke one dataset up into groups based upon the first letter of the name of each entry. Then we compared each record of the other dataset to only the groups that matched the first letters of all re-arrangements of its title. So "Frank's Bistro" in dataset 1 would be filed under F, and an entry named "Frank's Bistro" in dataset 2 would be compared only with the lists under F and B (to cover for "Bistro Frank"), avoiding exhaustive pairwise comparison.

Our precision, recall and F1 score on the training data were as follows:
Precision: 0.997014925373
Recall: 0.927777777778
F-Measure: 0.961151079137

